{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faedd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Schema Change Report Generator\n",
    "Jupyter Notebook for analyzing PostgreSQL schema changes between two timestamps\n",
    "\"\"\"\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbd9bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install psycopg2-binary pandas matplotlib seaborn\n",
    "# ! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "777221c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATABASE CONNECTION CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'test_db',\n",
    "    'user': 'jagdish_pandre',\n",
    "    'password': '',\n",
    "    'port': 5432\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_TIME = '2025-11-12 18:12:50'\n",
    "# END_TIME = '2025-11-12 18:25:50'\n",
    "\n",
    "START_TIME = '2025-11-12 18:13:39'\n",
    "END_TIME = '2025-11-12 18:18:55'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddd2d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n"
     ]
    }
   ],
   "source": [
    "def get_connection():\n",
    "    \"\"\"Create database connection\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"Database connection successful\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "conn = get_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a258d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SCHEMA CHANGE REPORT\n",
      "Period: 2025-11-12 18:12:50 to 2025-11-12 18:25:50\n",
      "================================================================================\n",
      "\n",
      " EXECUTIVE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "Total Snapshots: 6\n",
      "Schemas Affected: 1\n",
      "Tables Affected: 1\n",
      "Columns Affected: 17\n",
      "Total Changes: 26\n",
      "First Change: 2025-11-12 18:12:50.064149\n",
      "Last Change: 2025-11-12 18:24:02.083235\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. EXECUTIVE SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SCHEMA CHANGE REPORT\")\n",
    "print(f\"Period: {START_TIME} to {END_TIME}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_executive_summary = \"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT snapshot_id) as total_snapshots,\n",
    "    COUNT(DISTINCT schema_name) as schemas_affected,\n",
    "    COUNT(DISTINCT object_type_name) as tables_affected,\n",
    "    COUNT(DISTINCT object_subtype_name) as columns_affected,\n",
    "    COUNT(*) as total_changes,\n",
    "    MIN(processed_time) as first_change,\n",
    "    MAX(processed_time) as last_change\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s;\n",
    "\"\"\"\n",
    "\n",
    "df_summary = pd.read_sql_query(query_executive_summary, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n EXECUTIVE SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "for col in df_summary.columns:\n",
    "    print(f\"{col.replace('_', ' ').title()}: {df_summary[col].iloc[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59fe3dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CHANGE TYPE BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "       report_section change_type  count  percentage\n",
      "CHANGE TYPE BREAKDOWN       ADDED     15       57.69\n",
      "CHANGE TYPE BREAKDOWN     DELETED      5       19.23\n",
      "CHANGE TYPE BREAKDOWN    MODIFIED      4       15.38\n",
      "CHANGE TYPE BREAKDOWN     RENAMED      2        7.69\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2. CHANGE TYPE BREAKDOWN\n",
    "# ============================================\n",
    "\n",
    "# query_change_breakdown = \"\"\"\n",
    "# SELECT \n",
    "#     change_type,\n",
    "#     COUNT(*) as count,\n",
    "#     ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "# FROM pdcd_schema.md5_metadata_tbl\n",
    "# WHERE processed_time BETWEEN %s AND %s\n",
    "# GROUP BY change_type\n",
    "# ORDER BY count DESC;\n",
    "# \"\"\"\n",
    "query_change_breakdown = \"\"\"\n",
    "SELECT \n",
    "    'CHANGE TYPE BREAKDOWN' as report_section,\n",
    "    change_type,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "GROUP BY change_type\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "df_change_types = pd.read_sql_query(query_change_breakdown, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n CHANGE TYPE BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "print(df_change_types.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6eabd020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CHANGES BY TABLE\n",
      "--------------------------------------------------------------------------------\n",
      "     schema_name  table_name  total_changes  added  modified  deleted  renamed\n",
      "analytics_schema departments             26     15         4        5        2\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3. CHANGES BY TABLE\n",
    "# ============================================\n",
    "\n",
    "query_changes_by_table = \"\"\"\n",
    "SELECT \n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    COUNT(*) as total_changes,\n",
    "    COUNT(*) FILTER (WHERE change_type = 'ADDED') as added,\n",
    "    COUNT(*) FILTER (WHERE change_type = 'MODIFIED') as modified,\n",
    "    COUNT(*) FILTER (WHERE change_type = 'DELETED') as deleted,\n",
    "    COUNT(*) FILTER (WHERE change_type = 'RENAMED') as renamed\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "GROUP BY schema_name, object_type_name\n",
    "ORDER BY total_changes DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_by_table = pd.read_sql_query(query_changes_by_table, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n CHANGES BY TABLE\")\n",
    "print(\"-\" * 80)\n",
    "print(df_by_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a092238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COLUMN ADDITIONS\n",
      "--------------------------------------------------------------------------------\n",
      " snapshot_id             processed_time      schema_name  table_name      column_name         data_type max_length nullable                                                       default_value position\n",
      "           1 2025-11-12 18:12:50.064149 analytics_schema departments    department_id           integer                  NO nextval('analytics_schema.departments_department_id_seq'::regclass)        1\n",
      "           1 2025-11-12 18:12:50.070223 analytics_schema departments  department_name character varying        100       NO                                                                            2\n",
      "           1 2025-11-12 18:12:50.070249 analytics_schema departments    main_location character varying        100      YES                                                                            3\n",
      "           1 2025-11-12 18:12:50.070253 analytics_schema departments ternary_location character varying        100      YES                                                                            4\n",
      "           1 2025-11-12 18:12:50.070295 analytics_schema departments       manager_id           integer                 YES                                                                            5\n",
      "           1 2025-11-12 18:12:50.070322 analytics_schema departments      budget_code character varying         50      YES                                                                            6\n",
      "           2 2025-11-12 18:13:39.279653 analytics_schema departments           region              text                 YES                                                                            7\n",
      "           2 2025-11-12 18:13:39.279662 analytics_schema departments established_year           integer                 YES                                                                            8\n",
      "           3 2025-11-12 18:16:52.683044 analytics_schema departments  last_updated_by              text                 YES                                                                            9\n",
      "           3 2025-11-12 18:16:52.683055 analytics_schema departments budget_allocated           numeric                 YES                                                                           10\n",
      "           4 2025-11-12 18:17:55.671466 analytics_schema departments       updated_by              text                 YES                                                        CURRENT_USER        9\n",
      "           5 2025-11-12 18:19:30.783148 analytics_schema departments  total_employees           integer                 YES                                                                           11\n",
      "           5 2025-11-12 18:19:30.783193 analytics_schema departments    active_status           boolean                 YES                                                                true       12\n",
      "           6 2025-11-12 18:24:02.075893 analytics_schema departments        headcount            bigint                 YES                                                                           11\n",
      "           6 2025-11-12 18:24:02.083129 analytics_schema departments          remarks              text                 YES                                                                           13\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4. DETAILED COLUMN ADDITIONS\n",
    "# ============================================\n",
    "\n",
    "query_additions = \"\"\"\n",
    "SELECT \n",
    "    snapshot_id,\n",
    "    processed_time,\n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    object_subtype_name as column_name,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*data_type:([^,]+).*', '\\\\1') as data_type,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*max_length:([^,]*),.*', '\\\\1') as max_length,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*nullable:([^,]+).*', '\\\\1') as nullable,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*default_value:([^,]*),.*', '\\\\1') as default_value,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*ordinal_position:([0-9]+).*', '\\\\1') as position\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "    AND change_type = 'ADDED'\n",
    "ORDER BY processed_time, schema_name, object_type_name, object_subtype_name;\n",
    "\"\"\"\n",
    "\n",
    "df_additions = pd.read_sql_query(query_additions, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n COLUMN ADDITIONS\")\n",
    "print(\"-\" * 80)\n",
    "if df_additions.empty:\n",
    "    print(\"No columns added in this period.\")\n",
    "else:\n",
    "    print(df_additions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5391a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COLUMN MODIFICATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "            processed_time  table_name      column_name                          changes\n",
      "2025-11-12 18:13:39.279529 departments  department_name                Length: 100 â†’ 150\n",
      "2025-11-12 18:13:39.279585 departments    main_location                    Other changes\n",
      "2025-11-12 18:17:55.671346 departments budget_allocated Type: numeric â†’ double precision\n",
      "2025-11-12 18:17:55.671405 departments     founded_year                    Other changes\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. DETAILED COLUMN MODIFICATIONS\n",
    "# ============================================\n",
    "\n",
    "query_modifications = \"\"\"\n",
    "WITH current_changes AS (\n",
    "    SELECT \n",
    "        snapshot_id,\n",
    "        processed_time,\n",
    "        schema_name,\n",
    "        object_type_name,\n",
    "        object_subtype_name,\n",
    "        object_subtype_details,\n",
    "        object_md5\n",
    "    FROM pdcd_schema.md5_metadata_tbl\n",
    "    WHERE processed_time BETWEEN %s AND %s\n",
    "        AND change_type = 'MODIFIED'\n",
    "),\n",
    "previous_state AS (\n",
    "    SELECT DISTINCT ON (cc.schema_name, cc.object_type_name, cc.object_subtype_name)\n",
    "        cc.schema_name,\n",
    "        cc.object_type_name,\n",
    "        cc.object_subtype_name,\n",
    "        m.object_subtype_details as old_details,\n",
    "        m.processed_time as old_time\n",
    "    FROM current_changes cc\n",
    "    JOIN pdcd_schema.md5_metadata_tbl m \n",
    "        ON cc.schema_name = m.schema_name \n",
    "        AND cc.object_type_name = m.object_type_name\n",
    "        AND cc.object_subtype_name = m.object_subtype_name\n",
    "        AND m.processed_time < cc.processed_time\n",
    "    ORDER BY cc.schema_name, cc.object_type_name, cc.object_subtype_name, m.processed_time DESC\n",
    ")\n",
    "SELECT \n",
    "    cc.snapshot_id,\n",
    "    cc.processed_time,\n",
    "    cc.schema_name,\n",
    "    cc.object_type_name as table_name,\n",
    "    cc.object_subtype_name as column_name,\n",
    "    REGEXP_REPLACE(ps.old_details, '.*data_type:([^,]+).*', '\\\\1') as old_data_type,\n",
    "    REGEXP_REPLACE(cc.object_subtype_details, '.*data_type:([^,]+).*', '\\\\1') as new_data_type,\n",
    "    REGEXP_REPLACE(ps.old_details, '.*max_length:([^,]*),.*', '\\\\1') as old_max_length,\n",
    "    REGEXP_REPLACE(cc.object_subtype_details, '.*max_length:([^,]*),.*', '\\\\1') as new_max_length,\n",
    "    REGEXP_REPLACE(ps.old_details, '.*nullable:([^,]+).*', '\\\\1') as old_nullable,\n",
    "    REGEXP_REPLACE(cc.object_subtype_details, '.*nullable:([^,]+).*', '\\\\1') as new_nullable\n",
    "FROM current_changes cc\n",
    "LEFT JOIN previous_state ps \n",
    "    ON cc.schema_name = ps.schema_name \n",
    "    AND cc.object_type_name = ps.object_type_name\n",
    "    AND cc.object_subtype_name = ps.object_subtype_name\n",
    "ORDER BY cc.processed_time, cc.schema_name, cc.object_type_name;\n",
    "\"\"\"\n",
    "\n",
    "df_modifications = pd.read_sql_query(query_modifications, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n COLUMN MODIFICATIONS\")\n",
    "print(\"-\" * 80)\n",
    "if df_modifications.empty:\n",
    "    print(\"No columns modified in this period.\")\n",
    "else:\n",
    "    # Create readable change descriptions\n",
    "    changes = []\n",
    "    for _, row in df_modifications.iterrows():\n",
    "        change_desc = []\n",
    "        if row['old_data_type'] != row['new_data_type']:\n",
    "            change_desc.append(f\"Type: {row['old_data_type']} â†’ {row['new_data_type']}\")\n",
    "        if row['old_max_length'] != row['new_max_length']:\n",
    "            change_desc.append(f\"Length: {row['old_max_length']} â†’ {row['new_max_length']}\")\n",
    "        if row['old_nullable'] != row['new_nullable']:\n",
    "            change_desc.append(f\"Nullable: {row['old_nullable']} â†’ {row['new_nullable']}\")\n",
    "        changes.append('; '.join(change_desc) if change_desc else 'Other changes')\n",
    "    \n",
    "    df_modifications['changes'] = changes\n",
    "    print(df_modifications[['processed_time', 'table_name', 'column_name', 'changes']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea5e70c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COLUMN DELETIONS\n",
      "--------------------------------------------------------------------------------\n",
      " snapshot_id             processed_time      schema_name  table_name      column_name        data_type position\n",
      "           4 2025-11-12 18:17:55.671513 analytics_schema departments  last_updated_by             text        9\n",
      "           5 2025-11-12 18:19:30.783240 analytics_schema departments budget_allocated double precision       10\n",
      "           5 2025-11-12 18:19:30.783250 analytics_schema departments       updated_by             text        9\n",
      "           6 2025-11-12 18:24:02.083222 analytics_schema departments  total_employees          integer       11\n",
      "           6 2025-11-12 18:24:02.083235 analytics_schema departments    active_status          boolean       12\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6. COLUMN DELETIONS\n",
    "# ============================================\n",
    "\n",
    "query_deletions = \"\"\"\n",
    "SELECT \n",
    "    snapshot_id,\n",
    "    processed_time,\n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    object_subtype_name as column_name,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*data_type:([^,]+).*', '\\\\1') as data_type,\n",
    "    REGEXP_REPLACE(object_subtype_details, '.*ordinal_position:([0-9]+).*', '\\\\1') as position\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "    AND change_type = 'DELETED'\n",
    "ORDER BY processed_time, schema_name, object_type_name;\n",
    "\"\"\"\n",
    "\n",
    "df_deletions = pd.read_sql_query(query_deletions, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n COLUMN DELETIONS\")\n",
    "print(\"-\" * 80)\n",
    "if df_deletions.empty:\n",
    "    print(\"No columns deleted in this period.\")\n",
    "else:\n",
    "    print(df_deletions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92d04d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ COLUMN RENAMES\n",
      "--------------------------------------------------------------------------------\n",
      " snapshot_id             processed_time      schema_name  table_name          new_name                       object_md5\n",
      "           3 2025-11-12 18:16:52.682361 analytics_schema departments department_region 194c7795dfa2987255dfc248e379b863\n",
      "           3 2025-11-12 18:16:52.682897 analytics_schema departments      founded_year db7ef0dbfd52d44d7df67906ae719852\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7. COLUMN RENAMES -- Can be optimized to show old and new names\n",
    "# ============================================\n",
    "\n",
    "query_renames = \"\"\"\n",
    "SELECT \n",
    "    snapshot_id,\n",
    "    processed_time,\n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    object_subtype_name as new_name,\n",
    "    object_md5\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "    AND change_type = 'RENAMED'\n",
    "ORDER BY processed_time, schema_name, object_type_name;\n",
    "\"\"\"\n",
    "\n",
    "df_renames = pd.read_sql_query(query_renames, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\nðŸ”„ COLUMN RENAMES\")\n",
    "print(\"-\" * 80)\n",
    "if df_renames.empty:\n",
    "    print(\"No columns renamed in this period.\")\n",
    "else:\n",
    "    print(df_renames.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58b5dc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CHRONOLOGICAL TIMELINE\n",
      "--------------------------------------------------------------------------------\n",
      "            processed_time  snapshot_id                             description\n",
      "2025-11-12 18:12:50.064149            1        ADDED: departments.department_id\n",
      "2025-11-12 18:12:50.070223            1      ADDED: departments.department_name\n",
      "2025-11-12 18:12:50.070249            1        ADDED: departments.main_location\n",
      "2025-11-12 18:12:50.070253            1     ADDED: departments.ternary_location\n",
      "2025-11-12 18:12:50.070295            1           ADDED: departments.manager_id\n",
      "2025-11-12 18:12:50.070322            1          ADDED: departments.budget_code\n",
      "2025-11-12 18:13:39.279529            2   MODIFIED: departments.department_name\n",
      "2025-11-12 18:13:39.279585            2     MODIFIED: departments.main_location\n",
      "2025-11-12 18:13:39.279653            2               ADDED: departments.region\n",
      "2025-11-12 18:13:39.279662            2     ADDED: departments.established_year\n",
      "2025-11-12 18:16:52.682361            3  RENAMED: departments.department_region\n",
      "2025-11-12 18:16:52.682897            3       RENAMED: departments.founded_year\n",
      "2025-11-12 18:16:52.683044            3      ADDED: departments.last_updated_by\n",
      "2025-11-12 18:16:52.683055            3     ADDED: departments.budget_allocated\n",
      "2025-11-12 18:17:55.671346            4  MODIFIED: departments.budget_allocated\n",
      "2025-11-12 18:17:55.671405            4      MODIFIED: departments.founded_year\n",
      "2025-11-12 18:17:55.671466            4           ADDED: departments.updated_by\n",
      "2025-11-12 18:17:55.671513            4    DELETED: departments.last_updated_by\n",
      "2025-11-12 18:19:30.783148            5      ADDED: departments.total_employees\n",
      "2025-11-12 18:19:30.783193            5        ADDED: departments.active_status\n",
      "2025-11-12 18:19:30.783240            5   DELETED: departments.budget_allocated\n",
      "2025-11-12 18:19:30.783250            5         DELETED: departments.updated_by\n",
      "2025-11-12 18:24:02.075893            6            ADDED: departments.headcount\n",
      "2025-11-12 18:24:02.083129            6              ADDED: departments.remarks\n",
      "2025-11-12 18:24:02.083222            6    DELETED: departments.total_employees\n",
      "2025-11-12 18:24:02.083235            6      DELETED: departments.active_status\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 8. CHRONOLOGICAL TIMELINE\n",
    "# ============================================\n",
    "\n",
    "query_timeline = \"\"\"\n",
    "SELECT \n",
    "    snapshot_id,\n",
    "    processed_time,\n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    object_subtype_name as column_name,\n",
    "    change_type\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "ORDER BY processed_time, snapshot_id, schema_name, object_type_name;\n",
    "\"\"\"\n",
    "\n",
    "df_timeline = pd.read_sql_query(query_timeline, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n CHRONOLOGICAL TIMELINE\")\n",
    "print(\"-\" * 80)\n",
    "if df_timeline.empty:\n",
    "    print(\"No changes in this period.\")\n",
    "else:\n",
    "    # Add emoji indicators\n",
    "    emoji_map = {\n",
    "        'ADDED': '',\n",
    "        'MODIFIED': '',\n",
    "        'DELETED': '',\n",
    "        'RENAMED': ''\n",
    "    }\n",
    "    df_timeline['change_indicator'] = df_timeline['change_type'].map(emoji_map)\n",
    "    df_timeline['description'] = (df_timeline['change_indicator'] + ' ' + \n",
    "                                  df_timeline['change_type'] + ': ' +\n",
    "                                  df_timeline['table_name'] + '.' + \n",
    "                                  df_timeline['column_name'])\n",
    "    print(df_timeline[['processed_time', 'snapshot_id', 'description']].to_string(index=False))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d81acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HIGH-RISK CHANGES\n",
      "--------------------------------------------------------------------------------\n",
      "            processed_time      schema_name  table_name       column_name change_type                                        risk_level\n",
      "2025-11-12 18:17:55.671513 analytics_schema departments   last_updated_by     DELETED    CRITICAL: Column deleted - potential data loss\n",
      "2025-11-12 18:19:30.783240 analytics_schema departments  budget_allocated     DELETED    CRITICAL: Column deleted - potential data loss\n",
      "2025-11-12 18:19:30.783250 analytics_schema departments        updated_by     DELETED    CRITICAL: Column deleted - potential data loss\n",
      "2025-11-12 18:24:02.083222 analytics_schema departments   total_employees     DELETED    CRITICAL: Column deleted - potential data loss\n",
      "2025-11-12 18:24:02.083235 analytics_schema departments     active_status     DELETED    CRITICAL: Column deleted - potential data loss\n",
      "2025-11-12 18:13:39.279529 analytics_schema departments   department_name    MODIFIED           MEDIUM: Data type or constraint changed\n",
      "2025-11-12 18:13:39.279585 analytics_schema departments     main_location    MODIFIED           MEDIUM: Data type or constraint changed\n",
      "2025-11-12 18:17:55.671346 analytics_schema departments  budget_allocated    MODIFIED           MEDIUM: Data type or constraint changed\n",
      "2025-11-12 18:17:55.671405 analytics_schema departments      founded_year    MODIFIED           MEDIUM: Data type or constraint changed\n",
      "2025-11-12 18:16:52.682361 analytics_schema departments department_region     RENAMED  MEDIUM: Column renamed - update application code\n",
      "2025-11-12 18:16:52.682897 analytics_schema departments      founded_year     RENAMED  MEDIUM: Column renamed - update application code\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 9. HIGH-RISK CHANGES\n",
    "# ============================================\n",
    "\n",
    "query_high_risk = \"\"\"\n",
    "SELECT \n",
    "    processed_time,\n",
    "    schema_name,\n",
    "    object_type_name as table_name,\n",
    "    object_subtype_name as column_name,\n",
    "    change_type,\n",
    "    CASE \n",
    "        WHEN change_type = 'DELETED' THEN ' CRITICAL: Column deleted - potential data loss'\n",
    "        WHEN change_type = 'MODIFIED' THEN ' MEDIUM: Data type or constraint changed'\n",
    "        WHEN change_type = 'RENAMED' THEN ' MEDIUM: Column renamed - update application code'\n",
    "        ELSE ' LOW: Standard change'\n",
    "    END as risk_level\n",
    "FROM pdcd_schema.md5_metadata_tbl\n",
    "WHERE processed_time BETWEEN %s AND %s\n",
    "    AND change_type IN ('DELETED', 'MODIFIED', 'RENAMED')\n",
    "ORDER BY \n",
    "    CASE \n",
    "        WHEN change_type = 'DELETED' THEN 1\n",
    "        WHEN change_type = 'MODIFIED' THEN 2\n",
    "        ELSE 3\n",
    "    END,\n",
    "    processed_time;\n",
    "\"\"\"\n",
    "\n",
    "df_high_risk = pd.read_sql_query(query_high_risk, conn, params=(START_TIME, END_TIME))\n",
    "\n",
    "print(\"\\n HIGH-RISK CHANGES\")\n",
    "print(\"-\" * 80)\n",
    "if df_high_risk.empty:\n",
    "    print(\"No high-risk changes detected.\")\n",
    "else:\n",
    "    print(df_high_risk.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5fcb758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORT OPTIONS\n",
      "================================================================================\n",
      " Excel report exported successfully\n",
      " CSV export successful\n",
      "\n",
      " Database connection closed\n",
      "\n",
      "================================================================================\n",
      "REPORT GENERATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EXPORT OPTIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORT OPTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export to Excel\n",
    "try:\n",
    "    with pd.ExcelWriter(f'schema_change_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx') as writer:\n",
    "        df_summary.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        df_change_types.to_excel(writer, sheet_name='Change Types', index=False)\n",
    "        df_by_table.to_excel(writer, sheet_name='By Table', index=False)\n",
    "        df_additions.to_excel(writer, sheet_name='Additions', index=False)\n",
    "        df_modifications.to_excel(writer, sheet_name='Modifications', index=False)\n",
    "        df_deletions.to_excel(writer, sheet_name='Deletions', index=False)\n",
    "        df_renames.to_excel(writer, sheet_name='Renames', index=False)\n",
    "        df_timeline.to_excel(writer, sheet_name='Timeline', index=False)\n",
    "        df_high_risk.to_excel(writer, sheet_name='High Risk', index=False)\n",
    "    print(\" Excel report exported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\" Excel export failed: {e}\")\n",
    "\n",
    "# Export to CSV\n",
    "try:\n",
    "    df_timeline.to_csv(f'schema_changes_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)\n",
    "    print(\" CSV export successful\")\n",
    "except Exception as e:\n",
    "    print(f\" CSV export failed: {e}\")\n",
    "\n",
    "# Close connection\n",
    "if conn:\n",
    "    conn.close()\n",
    "    print(\"\\n Database connection closed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REPORT GENERATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
